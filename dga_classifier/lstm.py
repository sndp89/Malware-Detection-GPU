"""Train and test LSTM classifier"""
import dga_classifier.data as data
import numpy as np
from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.layers.embeddings import Embedding
from keras.layers.recurrent import LSTM
import sklearn
from sklearn.model_selection import train_test_split
from keras.utils import multi_gpu_model
from keras.models import load_model
import pandas as pd
import tldextract
import cPickle as pickle

def build_model(max_features, maxlen):
    """Build LSTM model"""
    model = Sequential()
    model.add(Embedding(max_features, 128, input_length=maxlen))
    model.add(LSTM(128))
    model.add(Dropout(0.5))
    model.add(Dense(1))
    model.add(Activation('sigmoid'))
    parallel_model = multi_gpu_model(model, gpus=4)
    parallel_model.compile(loss='binary_crossentropy',
                  optimizer='rmsprop')

    return parallel_model

def run(max_epoch=25, nfolds=1, batch_size=1024*4):
    """Run train/test on model"""
    indata = data.get_data()
    domain_list = pd.read_csv("proxy_log_04_10.csv")
    domain_list = domain_list.dropna()
 
    # Extract data and labels
    X = [x[1] for x in indata]
    labels = [x[0] for x in indata]

    # Generate a dictionary of valid characters
    valid_chars = {x:idx+1 for idx, x in enumerate(set(''.join(X)))}
    max_features = len(valid_chars) + 1
    maxlen = np.max([len(x) for x in X])

    #save the valid_chars as pickle file
    #valid_chars_pkl = open('valid_chars.pkl','wb')
    #pickle.dump(valid_chars, valid_chars_pkl)

    # Convert characters to int and pad
    X = [[valid_chars[y] for y in x] for x in X]
    X = sequence.pad_sequences(X, maxlen=maxlen)
    print max_features, maxlen

    domain_list['tld'] = domain_list['domain'].apply(lambda x: tldextract.extract(x).domain)
    test_data = domain_list['tld'].tolist()
    test_data1 = [[valid_chars[c] for c in x] for x in test_data]
    test_data2 = sequence.pad_sequences(test_data1, maxlen=maxlen)
    # Convert labels to 0-1
    y = [0 if x == 'benign' else 1 for x in labels]
    print 'length of y'
    print len(y)
    final_data = []
    
    for fold in range(nfolds):
        print "fold %u/%u" % (fold+1, nfolds)
        X_train, X_test, y_train, y_test, _, label_test = train_test_split(X, y, labels, 
                                                                           test_size=0.2)
        print 'Build model...'
        model = build_model(max_features, maxlen)
        print "Train..."
        X_train, X_holdout, y_train, y_holdout = train_test_split(X_train, y_train, test_size=0.05)
        best_iter = -1
        best_auc = 0.0
        out_data = {}

        for ep in range(max_epoch):
            model.fit(X_train, y_train, batch_size=batch_size, epochs=1)

            t_probs = model.predict(X_holdout)
            t_auc = sklearn.metrics.roc_auc_score(y_holdout, t_probs)

            print 'Epoch %d: auc = %f (best=%f)' % (ep, t_auc, best_auc)

            if t_auc > best_auc:
                best_auc = t_auc
                best_iter = ep

                probs = model.predict(X_test)
                 
                out_data = {'y':y_test, 'labels': label_test, 'probs':probs, 'epochs': ep}
                           # 'confusion_matrix': sklearn.metrics.confusion_matrix(y_test, probs > .5)}
                proxy_probs = model.predict(test_data2)
                for i in range(len(proxy_probs)):
                        print test_data[i], proxy_probs[i, 0]
               # print sklearn.metrics.confusion_matrix(y_test, probs > .5)
            else:
                # No longer improving...break and calc statistics
                if (ep-best_iter) > 2:
                    break
        model.summary()
        final_data.append(out_data)

    return final_data
